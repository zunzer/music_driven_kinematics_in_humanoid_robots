{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "287418a1",
   "metadata": {},
   "source": [
    "# Genre Identifier\n",
    "\n",
    "Creates a neural network that recognizes the genre of a song\n",
    "\n",
    "feature explanation courtesy of:\n",
    "https://navdeepsinghh.medium.com/identifying-the-genre-of-a-song-with-neural-networks-851db89c42f0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "baf5224f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.feature\n",
    "import librosa.display\n",
    "import glob\n",
    "import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.utils.np_utils import to_categorical\n",
    "# from keras.models import model_from_json\n",
    "from keras.models import load_model\n",
    "from ..DancingAgent import"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc09bce6",
   "metadata": {},
   "source": [
    "## 1. Load the data\n",
    "\n",
    "Load the data into one vector containg all the information. Data we use for training and testing is the GTZAN data set (https://www.tensorflow.org/datasets/catalog/gtzan)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "c65822c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_song_features(f):\n",
    "    y, _ = librosa.load(f)\n",
    "\n",
    "    # get Mel-frequency cepstral coefficients and normalize\n",
    "    mfcc = librosa.feature.mfcc(y)\n",
    "    mfcc /= np.amax(np.absolute(mfcc))\n",
    "    return np.ndarray.flatten(mfcc)[:25000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "7d9f42c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 100 songs in blues genre...\n",
      "Processing 100 songs in country genre...\n",
      "Processing 100 songs in disco genre...\n",
      "Processing 100 songs in hiphop genre...\n",
      "Processing 100 songs in jazz genre...\n",
      "Processing 100 songs in metal genre...\n",
      "Processing 100 songs in pop genre...\n",
      "Processing 100 songs in reggae genre...\n",
      "Processing 100 songs in rock genre...\n"
     ]
    }
   ],
   "source": [
    "GENRES = ['blues', 'classical', 'country', 'disco', 'hiphop', 'jazz', 'metal', 'pop', 'reggae', 'rock']\n",
    "all_features = []\n",
    "all_labels = []\n",
    "\n",
    "# load all songs from the gtzan data set\n",
    "for genre in GENRES:\n",
    "    sound_files = glob.glob('genres/' + genre + '/*.wav')\n",
    "    print('Processing %d songs in %s genre...' % (len(sound_files), genre))\n",
    "    for f in sound_files:\n",
    "        extracted_features = extract_song_features(f)\n",
    "        all_features.append(extracted_features)\n",
    "        all_labels.append(genre)\n",
    "\n",
    "# convert labels to one-hot encoding\n",
    "label_uniq_ids, label_row_ids = np.unique(all_labels, return_inverse=True)\n",
    "label_row_ids = label_row_ids.astype(np.int32, copy=False)\n",
    "onehot_labels = to_categorical(label_row_ids, len(label_uniq_ids))\n",
    "\n",
    "# store features and labels\n",
    "features = np.stack(all_features)\n",
    "labels = onehot_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "0d7309a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(900, 25000)\n",
      "(900, 9)\n"
     ]
    }
   ],
   "source": [
    "# get shapes\n",
    "print(np.shape(features))\n",
    "print(np.shape(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56bf6ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "208f478e",
   "metadata": {},
   "source": [
    "## 2. Prepare the data set and build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "53856691",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test(data, training_split=0.8):\n",
    "    \"\"\"\n",
    "    this splits according to the ration we want to split with\n",
    "    \"\"\"\n",
    "    np.random.shuffle(data)\n",
    "    split_idx = int(len(data) * training_split)\n",
    "    train, test = data[:split_idx, :], data[split_idx:, :]\n",
    "\n",
    "    #      train data,     train labels,  test data,      test labels\n",
    "    return train[:, :-10], train[:, -10:], test[:, :-10], test[:, -10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "0b890b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(train):\n",
    "    \"\"\"\n",
    "    build the model; in our case it is a perceptron with 100 layers\n",
    "    \"\"\"\n",
    "    print(f\"shape of input data: {np.shape(train)[1]}\")\n",
    "    nn_model = Sequential([\n",
    "        Dense(90, input_dim=np.shape(train)[1]),\n",
    "        Activation('relu'),\n",
    "        Dense(9),\n",
    "        Activation('softmax'),\n",
    "    ])\n",
    "\n",
    "\n",
    "    # specify which techniques you want to use for training\n",
    "    nn_model.compile(optimizer='adam',\n",
    "                     loss='categorical_crossentropy',\n",
    "                     metrics=['accuracy'])\n",
    "    print(nn_model.summary())\n",
    "    return nn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "b1735c75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of input data: 25000\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_19 (Dense)             (None, 90)                2250090   \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 90)                0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 9)                 819       \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 9)                 0         \n",
      "=================================================================\n",
      "Total params: 2,250,909\n",
      "Trainable params: 2,250,909\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# last column has genre, turn it into unique ids\n",
    "all_data = np.column_stack((features, labels))\n",
    "\n",
    "# split into training and test data\n",
    "train_input, train_labels, test_input, test_labels = split_train_test(all_data)\n",
    "\n",
    "# build the model\n",
    "model = build_model(train_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "ff16acac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(720, 25000)\n"
     ]
    }
   ],
   "source": [
    "print(train_input.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5105c82b",
   "metadata": {},
   "source": [
    "## 3. Run the process\n",
    "\n",
    "Now, we train our model and evaluate it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "5f5c40b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 576 samples, validate on 144 samples\n",
      "Epoch 1/10\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 2.0883 - accuracy: 0.2639 - val_loss: 1.9495 - val_accuracy: 0.2639\n",
      "Epoch 2/10\n",
      "576/576 [==============================] - 1s 1ms/step - loss: 1.4023 - accuracy: 0.5052 - val_loss: 1.8073 - val_accuracy: 0.3611\n",
      "Epoch 3/10\n",
      "576/576 [==============================] - 1s 1ms/step - loss: 1.0656 - accuracy: 0.6580 - val_loss: 1.6356 - val_accuracy: 0.4444\n",
      "Epoch 4/10\n",
      "576/576 [==============================] - 1s 1ms/step - loss: 0.7986 - accuracy: 0.7778 - val_loss: 1.6089 - val_accuracy: 0.4583\n",
      "Epoch 5/10\n",
      "576/576 [==============================] - 1s 1ms/step - loss: 0.5940 - accuracy: 0.8542 - val_loss: 1.5852 - val_accuracy: 0.4444\n",
      "Epoch 6/10\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.4827 - accuracy: 0.8854 - val_loss: 1.6666 - val_accuracy: 0.4861\n",
      "Epoch 7/10\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.3762 - accuracy: 0.9306 - val_loss: 1.6783 - val_accuracy: 0.4722\n",
      "Epoch 8/10\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.2663 - accuracy: 0.9722 - val_loss: 1.5857 - val_accuracy: 0.4722\n",
      "Epoch 9/10\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.2000 - accuracy: 0.9948 - val_loss: 1.6957 - val_accuracy: 0.4792\n",
      "Epoch 10/10\n",
      "576/576 [==============================] - 1s 2ms/step - loss: 0.1637 - accuracy: 0.9983 - val_loss: 1.6661 - val_accuracy: 0.5069\n",
      "180/180 [==============================] - 0s 263us/step\n",
      "Done!\n",
      "Loss: 1.5543, accuracy: 0.4778\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "model.fit(train_input, train_labels, epochs=10, batch_size=32,\n",
    "          validation_split=0.2)\n",
    "\n",
    "# now get the performance indicators\n",
    "loss, acc = model.evaluate(test_input, test_labels, batch_size=32)\n",
    "\n",
    "print(\"Done!\")\n",
    "print(\"Loss: %.4f, accuracy: %.4f\" % (loss, acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13f5caf",
   "metadata": {},
   "source": [
    "## 4. Store the classifier to use it in thinking.py\n",
    "\n",
    "use JSON for simplicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "76d95f94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# save model\n",
    "model.save(\"model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49df6159",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "36daa1b2",
   "metadata": {},
   "source": [
    "## 5. Retrieve model and test it to see if everything works\n",
    "\n",
    "make sure you have the correct version of h5py (2.10.0). This creates warnings at one end, but was the only thing that worked for me."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "01208bd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_19 (Dense)             (None, 90)                2250090   \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 90)                0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 9)                 819       \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 9)                 0         \n",
      "=================================================================\n",
      "Total params: 2,250,909\n",
      "Trainable params: 2,250,909\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "model = load_model('model.h5')\n",
    "print(\"Loaded model from disk\")\n",
    "# summarize model.\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "6bd409cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 25000)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate loaded model on single song\n",
    "test_genre = \"rock\"\n",
    "own_audio = extract_song_features(\"../recordings/output.wav\")\n",
    "some_audio = extract_song_features(\"genres/\" + test_genre + \"/\" + test_genre + \".00000.wav\")\n",
    "\n",
    "# reshape for input\n",
    "test_in = own_audio[np.newaxis,:]\n",
    "test_in.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c036205c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "775932c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['blues', 'country', 'disco', 'hiphop', 'jazz', 'metal', 'pop', 'reggae', 'rock']\n",
      "[1.05e-02 4.28e-03 6.06e-04 1.29e-03 8.19e-01 1.59e-01 1.08e-05 2.54e-03\n",
      " 2.88e-03]\n"
     ]
    }
   ],
   "source": [
    "# now predict on test in\n",
    "model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "score = model.predict(test_in, verbose=0)\n",
    "\n",
    "#np.set_printoptions(precision=2)\n",
    "print(GENRES)\n",
    "print(score[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "e270545b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "real genre: rock\n",
      "predicted genre: jazz\n"
     ]
    }
   ],
   "source": [
    "# now output the name\n",
    "max_class = score.argmax(axis=-1)\n",
    "print(f\"real genre: {test_genre}\\npredicted genre: {GENRES[max_class[0]]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ef5823",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}